{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7faa410",
   "metadata": {},
   "source": [
    "# !!!TEST NEW GAME POV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "731b3442",
   "metadata": {},
   "source": [
    "## CONFIG AND MENU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e8d65e46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MENU chosen: {'mode': 'Train', 'algorithm': 'Actor-Critic', 'params': {'episodes': 50, 'alpha': 0.1, 'gamma': 0.99, 'epsilon': 0.2, 'shooter_speed': 50, 'defender_speed': 50, 'ball_speed': 50}}\n"
     ]
    }
   ],
   "source": [
    "# ----------------- CELL 1: CONFIG & PYGAME MENU -----------------\n",
    "import pygame, sys, os, random, math, time\n",
    "import numpy as np\n",
    "\n",
    "# Basic config defaults (editable in menu)\n",
    "CONFIG = {\n",
    "    \"SCREEN_WIDTH\": 960,\n",
    "    \"SCREEN_HEIGHT\": 640,\n",
    "    \"GRID_SIZE\": 64,             # smaller grid for smoother/finer movement\n",
    "    \"PLAYER_SPEED\": 6,\n",
    "    \"BALL_SPEED\": 14,\n",
    "    \"EPISODES\": 200,\n",
    "    \"ALPHA\": 0.1,\n",
    "    \"GAMMA\": 0.99,\n",
    "    \"EPSILON\": 0.2,\n",
    "    \"FPS\": 30,\n",
    "    \"HOOP_COLUMN_OFFSET\": 100   # how far from right edge the hoop column starts\n",
    "}\n",
    "\n",
    "# Menu result container (filled by run_menu())\n",
    "MENU = {\n",
    "    \"mode\": None,         # \"Train\" or \"Play\"\n",
    "    \"algorithm\": None,    # \"Q-Learning\", \"Monte Carlo\", \"Actor-Critic\"\n",
    "    \"params\": {}          # filled with numeric params\n",
    "}\n",
    "\n",
    "# Helper: text input in pygame to enter numeric values\n",
    "def pygame_numeric_input(screen, caption, initial=\"\", pos=(120,300), max_chars=10):\n",
    "    font = pygame.font.SysFont(None, 28)\n",
    "    clock = pygame.time.Clock()\n",
    "    val = initial\n",
    "    active = True\n",
    "    while active:\n",
    "        for ev in pygame.event.get():\n",
    "            if ev.type == pygame.QUIT:\n",
    "                pygame.quit(); sys.exit()\n",
    "            if ev.type == pygame.KEYDOWN:\n",
    "                if ev.key == pygame.K_RETURN:\n",
    "                    return val if val!=\"\" else None\n",
    "                elif ev.key == pygame.K_ESCAPE:\n",
    "                    return None\n",
    "                elif ev.key == pygame.K_BACKSPACE:\n",
    "                    val = val[:-1]\n",
    "                else:\n",
    "                    ch = ev.unicode\n",
    "                    if (ch.isdigit() or ch == \".\") and len(val) < max_chars:\n",
    "                        val += ch\n",
    "        screen.fill((12,12,12))\n",
    "        title = font.render(caption, True, (220,220,220))\n",
    "        screen.blit(title, (pos[0], pos[1]-50))\n",
    "        pygame.draw.rect(screen, (200,200,200), (pos[0]-6, pos[1]-6, 440, 40), 2)\n",
    "        txt = font.render(val, True, (255,255,255))\n",
    "        screen.blit(txt, (pos[0], pos[1]))\n",
    "        hint = font.render(\"Enter=OK  Esc=Cancel\", True, (180,180,180))\n",
    "        screen.blit(hint, (pos[0], pos[1]+60))\n",
    "        pygame.display.flip()\n",
    "        clock.tick(30)\n",
    "\n",
    "# Main menu UI: choose Train / Play / Quit; if Train choose algorithm and numeric params\n",
    "def run_menu():\n",
    "    pygame.init()\n",
    "    screen = pygame.display.set_mode((640, 420))\n",
    "    pygame.display.set_caption(\"Basketball RL - Menu\")\n",
    "    font = pygame.font.SysFont(None, 36)\n",
    "    small = pygame.font.SysFont(None, 22)\n",
    "    clock = pygame.time.Clock()\n",
    "\n",
    "    options = [\"Train\", \"Play\", \"Quit\"]\n",
    "    sel = 0\n",
    "    while True:\n",
    "        screen.fill((18,18,18))\n",
    "        draw = lambda txt, pos, c: screen.blit(font.render(txt, True, c), pos)\n",
    "        draw(\"Basketball RL - Menu\", (160, 30), (255,220,120))\n",
    "        for i, o in enumerate(options):\n",
    "            color = (255,180,120) if i==sel else (220,220,220)\n",
    "            draw(o, (260, 120 + i*60), color)\n",
    "        draw(\"Use ↑/↓ to move, Enter to select\", (180, 320), (180,180,180))\n",
    "        pygame.display.flip()\n",
    "\n",
    "        for ev in pygame.event.get():\n",
    "            if ev.type == pygame.QUIT:\n",
    "                pygame.quit(); sys.exit()\n",
    "            if ev.type == pygame.KEYDOWN:\n",
    "                if ev.key == pygame.K_UP:\n",
    "                    sel = (sel - 1) % len(options)\n",
    "                elif ev.key == pygame.K_DOWN:\n",
    "                    sel = (sel + 1) % len(options)\n",
    "                elif ev.key == pygame.K_RETURN:\n",
    "                    choice = options[sel]\n",
    "                    if choice == \"Quit\":\n",
    "                        pygame.quit(); sys.exit()\n",
    "                    MENU[\"mode\"] = choice\n",
    "                    break\n",
    "        if MENU[\"mode\"] is not None:\n",
    "            break\n",
    "        clock.tick(30)\n",
    "\n",
    "    # If Train -> choose algorithm\n",
    "    if MENU[\"mode\"] == \"Train\":\n",
    "        algos = [\"Q-Learning\", \"Monte Carlo\", \"Actor-Critic\"]\n",
    "        sel = 0\n",
    "        choosing = True\n",
    "        while choosing:\n",
    "            screen.fill((12,12,30))\n",
    "            screen.blit(font.render(\"Choose Algorithm\", True, (200,200,240)), (200,60))\n",
    "            for i, a in enumerate(algos):\n",
    "                color = (120,255,140) if i==sel else (200,200,200)\n",
    "                screen.blit(font.render(a, True, color), (200, 150 + i*50))\n",
    "            screen.blit(small.render(\"Use ↑/↓ Enter to select\", True, (180,180,180)), (200, 320))\n",
    "            pygame.display.flip()\n",
    "            for ev in pygame.event.get():\n",
    "                if ev.type == pygame.QUIT:\n",
    "                    pygame.quit(); sys.exit()\n",
    "                if ev.type == pygame.KEYDOWN:\n",
    "                    if ev.key == pygame.K_UP:\n",
    "                        sel = (sel - 1) % len(algos)\n",
    "                    elif ev.key == pygame.K_DOWN:\n",
    "                        sel = (sel + 1) % len(algos)\n",
    "                    elif ev.key == pygame.K_RETURN:\n",
    "                        MENU[\"algorithm\"] = algos[sel]\n",
    "                        choosing = False\n",
    "            clock.tick(30)\n",
    "\n",
    "        # Parameter editor\n",
    "        params = {}\n",
    "        screen.fill((10,10,10)); pygame.display.flip()\n",
    "        val = pygame_numeric_input(screen, \"Episodes (int):\", str(CONFIG[\"EPISODES\"]), pos=(120,220))\n",
    "        params[\"episodes\"] = int(val) if val and val.isdigit() else CONFIG[\"EPISODES\"]\n",
    "\n",
    "        val = pygame_numeric_input(screen, \"Alpha (learning rate):\", str(CONFIG[\"ALPHA\"]), pos=(120,220))\n",
    "        try: params[\"alpha\"] = float(val) if val is not None else CONFIG[\"ALPHA\"]\n",
    "        except: params[\"alpha\"] = CONFIG[\"ALPHA\"]\n",
    "\n",
    "        val = pygame_numeric_input(screen, \"Gamma (discount):\", str(CONFIG[\"GAMMA\"]), pos=(120,220))\n",
    "        try: params[\"gamma\"] = float(val) if val is not None else CONFIG[\"GAMMA\"]\n",
    "        except: params[\"gamma\"] = CONFIG[\"GAMMA\"]\n",
    "\n",
    "        val = pygame_numeric_input(screen, \"Epsilon (exploration):\", str(CONFIG[\"EPSILON\"]), pos=(120,220))\n",
    "        try: params[\"epsilon\"] = float(val) if val is not None else CONFIG[\"EPSILON\"]\n",
    "        except: params[\"epsilon\"] = CONFIG[\"EPSILON\"]\n",
    "\n",
    "        val = pygame_numeric_input(screen, \"Shooter speed (int):\", str(CONFIG[\"PLAYER_SPEED\"]), pos=(120,220))\n",
    "        params[\"shooter_speed\"] = int(val) if val and val.isdigit() else CONFIG[\"PLAYER_SPEED\"]\n",
    "\n",
    "        val = pygame_numeric_input(screen, \"Defender speed (int):\", str(CONFIG[\"PLAYER_SPEED\"]), pos=(120,220))\n",
    "        params[\"defender_speed\"] = int(val) if val and val.isdigit() else CONFIG[\"PLAYER_SPEED\"]\n",
    "\n",
    "        val = pygame_numeric_input(screen, \"Ball speed (int):\", str(CONFIG[\"BALL_SPEED\"]), pos=(120,220))\n",
    "        params[\"ball_speed\"] = int(val) if val and val.isdigit() else CONFIG[\"BALL_SPEED\"]\n",
    "\n",
    "        MENU[\"params\"] = params\n",
    "\n",
    "    # If Play -> ask whether Defender should be manual (arrow keys) or use agent (trained)\n",
    "    elif MENU[\"mode\"] == \"Play\":\n",
    "        screen.fill((10,10,10)); pygame.display.flip()\n",
    "        choosing = True\n",
    "        font_small = pygame.font.SysFont(None, 26)\n",
    "        manual = False\n",
    "        while choosing:\n",
    "            screen.fill((14,14,14))\n",
    "            screen.blit(font.render(\"Play Mode\", True, (200,220,200)), (240, 60))\n",
    "            screen.blit(font_small.render(\"Defender manual? (Arrow keys)  Y = Yes / N = No (use trained agent if available)\", True, (200,200,200)), (50, 150))\n",
    "            pygame.display.flip()\n",
    "            for ev in pygame.event.get():\n",
    "                if ev.type == pygame.QUIT:\n",
    "                    pygame.quit(); sys.exit()\n",
    "                if ev.type == pygame.KEYDOWN:\n",
    "                    if ev.key == pygame.K_y:\n",
    "                        manual = True; choosing = False\n",
    "                    elif ev.key == pygame.K_n:\n",
    "                        manual = False; choosing = False\n",
    "        MENU[\"params\"] = {\n",
    "            \"manual_defender\": manual,\n",
    "            \"shooter_speed\": CONFIG[\"PLAYER_SPEED\"],\n",
    "            \"defender_speed\": CONFIG[\"PLAYER_SPEED\"],\n",
    "            \"ball_speed\": CONFIG[\"BALL_SPEED\"]\n",
    "        }\n",
    "\n",
    "    print(\"MENU chosen:\", MENU)\n",
    "    pygame.quit()\n",
    "    return MENU\n",
    "\n",
    "def draw_text(screen, text, pos, font, color=(255,255,255)):\n",
    "    screen.blit(font.render(text, True, color), pos)\n",
    "\n",
    "MENU = run_menu()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9103edd",
   "metadata": {},
   "source": [
    "## ENVIRONMENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c3980678",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------- CELL 2: BasketballEnv -----------------\n",
    "import pygame, os, math, random\n",
    "import numpy as np\n",
    "\n",
    "class BasketballEnv:\n",
    "    def __init__(self, cfg, render_fps=None):\n",
    "        self.cfg = cfg\n",
    "        self.W = cfg[\"SCREEN_WIDTH\"]\n",
    "        self.H = cfg[\"SCREEN_HEIGHT\"]\n",
    "        self.grid = cfg[\"GRID_SIZE\"]   # make smaller in CFG for smoother movement\n",
    "        self.hoop_x = self.W - cfg[\"HOOP_COLUMN_OFFSET\"]\n",
    "        self.player_speed_default = cfg[\"PLAYER_SPEED\"]\n",
    "        self.ball_speed_default = cfg[\"BALL_SPEED\"]\n",
    "        self.render_fps = render_fps if render_fps else cfg[\"FPS\"]\n",
    "\n",
    "        # Pygame init and screen (do not call quit here)\n",
    "        pygame.init()\n",
    "        self.screen = pygame.display.set_mode((self.W, self.H))\n",
    "        pygame.display.set_caption(\"Basketball RL - Game\")\n",
    "\n",
    "        # Load images if available (placeholders otherwise)\n",
    "        def load_or_placeholder(path, size, label):\n",
    "            if os.path.exists(path):\n",
    "                try:\n",
    "                    img = pygame.image.load(path).convert_alpha()\n",
    "                    return pygame.transform.smoothscale(img, size)\n",
    "                except:\n",
    "                    pass\n",
    "            surf = pygame.Surface(size, pygame.SRCALPHA)\n",
    "            surf.fill((40,40,40))\n",
    "            pygame.draw.rect(surf, (200,200,200), surf.get_rect(), 2)\n",
    "            f = pygame.font.SysFont(None, 18)\n",
    "            surf.blit(f.render(label, True, (220,220,220)), (4,4))\n",
    "            return surf\n",
    "\n",
    "        # Default placeholders\n",
    "        self.court_img = load_or_placeholder(\"halfcourt.png\", (self.W, self.H), \"Court\")\n",
    "        self.shooter_img = load_or_placeholder(\"shooter.png\", (44,44), \"Shooter\")\n",
    "        self.defender_img = load_or_placeholder(\"defender (2).png\", (44,44), \"Defender\")\n",
    "        self.hoop_img = load_or_placeholder(\"ring.png\", (64,24), \"Hoop\")\n",
    "        self.ball_img = load_or_placeholder(\"basketball.png\", (18,18), \"Ball\")\n",
    "\n",
    "        # Entity rectangles (positions)\n",
    "        self.episode = 0   # will be set by training loop\n",
    "        self.reset()\n",
    "\n",
    "        # --- Global cumulative stats across episodes ---\n",
    "        self.global_shooter_score = 0\n",
    "        self.global_defender_blocks = 0\n",
    "        self.global_reward = 0\n",
    "\n",
    "        # Font\n",
    "        self.font = pygame.font.SysFont(None, 24)\n",
    "        self.clock = pygame.time.Clock()\n",
    "\n",
    "    def reset(self, shooter_pos=None, defender_pos=None, shooter_speed=None, defender_speed=None, ball_speed=None):\n",
    "        self.shooter_speed = shooter_speed if shooter_speed is not None else self.player_speed_default\n",
    "        self.defender_speed = defender_speed if defender_speed is not None else self.player_speed_default\n",
    "        self.ball_speed = ball_speed if ball_speed is not None else self.ball_speed_default\n",
    "\n",
    "        self.shooter = pygame.Rect(80, self.H//2 - 22, 44, 44)\n",
    "        self.defender = pygame.Rect(self.W//2, self.H//2 - 22, 44, 44)\n",
    "        if shooter_pos: self.shooter.topleft = shooter_pos\n",
    "        if defender_pos: self.defender.topleft = defender_pos\n",
    "\n",
    "        # Ball follows shooter until shot\n",
    "        self.ball_x = self.shooter.centerx\n",
    "        self.ball_y = self.shooter.centery\n",
    "        self.ball_in_motion = False\n",
    "        self.ball_vel_x = 0\n",
    "\n",
    "        # Per-episode stats (reset each ep)\n",
    "        self.shooter_score = 0\n",
    "        self.defender_blocks = 0\n",
    "\n",
    "        self.done = False\n",
    "        self.last_reward = 0\n",
    "        return self._get_state()\n",
    "\n",
    "    def _get_state(self):\n",
    "        # Discrete state representation\n",
    "        sx = max(0, min(self.W - 1, self.shooter.x)) // self.grid\n",
    "        sy = max(0, min(self.H - 1, self.shooter.y)) // self.grid\n",
    "        dx = max(0, min(self.W - 1, self.defender.x)) // self.grid\n",
    "        dy = max(0, min(self.H - 1, self.defender.y)) // self.grid\n",
    "        ball = 1 if self.ball_in_motion else 0\n",
    "        return (sx, sy, dx, dy, ball)\n",
    "\n",
    "    def _constrain_positions(self):\n",
    "        max_shooter_x = self.hoop_x - 60\n",
    "        if self.shooter.x > max_shooter_x:\n",
    "            self.shooter.x = max_shooter_x\n",
    "        max_def_x = self.hoop_x - 20\n",
    "        if self.defender.x > max_def_x:\n",
    "            self.defender.x = max_def_x\n",
    "\n",
    "        for r in [self.shooter, self.defender]:\n",
    "            r.x = max(0, min(self.W - r.width, r.x))\n",
    "            r.y = max(0, min(self.H - r.height, r.y))\n",
    "\n",
    "    def step(self, action_defender, action_shooter=None, shoot=False):\n",
    "        self.last_reward = 0\n",
    "        self.done = False\n",
    "\n",
    "        # Move shooter\n",
    "        if action_shooter == \"UP\":\n",
    "            self.shooter.y -= self.shooter_speed\n",
    "        elif action_shooter == \"DOWN\":\n",
    "            self.shooter.y += self.shooter_speed\n",
    "        elif action_shooter == \"LEFT\":\n",
    "            self.shooter.x -= self.shooter_speed\n",
    "        elif action_shooter == \"RIGHT\":\n",
    "            self.shooter.x += self.shooter_speed\n",
    "\n",
    "        # Ball follows shooter if not in motion\n",
    "        if not self.ball_in_motion:\n",
    "            self.ball_x = self.shooter.centerx\n",
    "            self.ball_y = self.shooter.centery\n",
    "\n",
    "        # Move defender\n",
    "        if action_defender == \"UP\":\n",
    "            self.defender.y -= self.defender_speed\n",
    "        elif action_defender == \"DOWN\":\n",
    "            self.defender.y += self.defender_speed\n",
    "        elif action_defender == \"LEFT\":\n",
    "            self.defender.x -= self.defender_speed\n",
    "        elif action_defender == \"RIGHT\":\n",
    "            self.defender.x += self.defender_speed\n",
    "\n",
    "        self._constrain_positions()\n",
    "\n",
    "        # Shooting logic\n",
    "        if shoot and not self.ball_in_motion:\n",
    "            self.ball_in_motion = True\n",
    "            self.ball_x = self.shooter.centerx\n",
    "            self.ball_y = self.shooter.centery\n",
    "            self.ball_vel_x = self.ball_speed\n",
    "\n",
    "        if self.ball_in_motion:\n",
    "            self.ball_x += self.ball_vel_x\n",
    "\n",
    "            # Check block\n",
    "            dist_x = abs(self.defender.centerx - self.ball_x)\n",
    "            dist_y = abs(self.defender.centery - self.ball_y)\n",
    "            if dist_x < 36 and dist_y < 36: \n",
    "                self.last_reward = +10\n",
    "                self.defender_blocks += 1\n",
    "                self.global_defender_blocks += 1\n",
    "                self.global_reward += self.last_reward\n",
    "                self.ball_in_motion = False\n",
    "                self.done = True\n",
    "\n",
    "            # Check score only if ball passes hoop *and* within vertical range\n",
    "            elif self.ball_x >= self.hoop_x:\n",
    "                hoop_y = self.H//2 - self.hoop_img.get_height()//2\n",
    "                hoop_top = hoop_y\n",
    "                hoop_bottom = hoop_y + self.hoop_img.get_height()\n",
    "                if hoop_top <= self.ball_y <= hoop_bottom:\n",
    "                    self.last_reward = -10\n",
    "                    self.shooter_score += 1\n",
    "                    self.global_shooter_score += 1\n",
    "                    self.global_reward += self.last_reward\n",
    "                else:\n",
    "                    self.last_reward = 0  # miss = no reward\n",
    "                self.ball_in_motion = False\n",
    "                self.done = True\n",
    "\n",
    "        return self._get_state(), self.last_reward, self.done, {\n",
    "            \"blocks\": self.defender_blocks,\n",
    "            \"shooter_score\": self.shooter_score\n",
    "        }\n",
    "\n",
    "    def render(self):\n",
    "        self.screen.blit(self.court_img, (0,0))\n",
    "        hoop_y = self.H//2 - self.hoop_img.get_height()//2\n",
    "        self.screen.blit(self.hoop_img, (self.hoop_x, hoop_y))\n",
    "        self.screen.blit(self.shooter_img, (self.shooter.x, self.shooter.y))\n",
    "        self.screen.blit(self.defender_img, (self.defender.x, self.defender.y))\n",
    "\n",
    "        if self.ball_in_motion:\n",
    "            self.screen.blit(self.ball_img, (int(self.ball_x - self.ball_img.get_width()/2),\n",
    "                                             int(self.ball_y - self.ball_img.get_height()/2)))\n",
    "        else:\n",
    "            self.screen.blit(self.ball_img, (self.shooter.centerx - self.ball_img.get_width()//2,\n",
    "                                             self.shooter.centery - self.ball_img.get_height()//2))\n",
    "\n",
    "        # --- SCOREBOARD TEXT (CUMULATIVE) ---\n",
    "        txt = (f\"Episode: {self.episode}  |  \"\n",
    "               f\"Blocks (Total): {self.global_defender_blocks}  |  \"\n",
    "               f\"Shooter Score (Total): {self.global_shooter_score}  |  \"\n",
    "               f\"Reward (Total): {self.global_reward}\")\n",
    "        score_surf = self.font.render(txt, True, (255,255,255))\n",
    "        self.screen.blit(score_surf, (16,16))\n",
    "\n",
    "        pygame.display.flip()\n",
    "        self.clock.tick(self.render_fps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "251759b2",
   "metadata": {},
   "source": [
    "## ALGORITHMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "41e853df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------- CELL 3: RL ALGORITHMS -----------------\n",
    "import math, random\n",
    "from collections import defaultdict\n",
    "\n",
    "ACTION_LIST = [\"UP\",\"DOWN\",\"LEFT\",\"RIGHT\",\"STAY\",\"SHOOT\"]\n",
    "# For defender agent we will not include SHOOT action - defender's actions are movement & stay:\n",
    "DEF_ACTIONS = [\"UP\",\"DOWN\",\"LEFT\",\"RIGHT\",\"STAY\"]\n",
    "\n",
    "class QLearningAgent:\n",
    "    def __init__(self, env, params):\n",
    "        self.env = env\n",
    "        self.alpha = params.get(\"alpha\", 0.1)\n",
    "        self.gamma = params.get(\"gamma\", 0.99)\n",
    "        self.epsilon = params.get(\"epsilon\", 0.2)\n",
    "        self.q = defaultdict(lambda: np.zeros(len(DEF_ACTIONS)))  # tabular\n",
    "\n",
    "    def state_key(self, s):\n",
    "        # s is the tuple from env._get_state()\n",
    "        return tuple(s)\n",
    "\n",
    "    def choose_action(self, state):\n",
    "        key = self.state_key(state)\n",
    "        if random.random() < self.epsilon:\n",
    "            return random.choice(DEF_ACTIONS)\n",
    "        vals = self.q[key]\n",
    "        return DEF_ACTIONS[int(np.argmax(vals))]\n",
    "\n",
    "    def learn_step(self, state, action, reward, next_state):\n",
    "        sk = self.state_key(state)\n",
    "        nk = self.state_key(next_state)\n",
    "        a_idx = DEF_ACTIONS.index(action)\n",
    "        best_next = np.max(self.q[nk])\n",
    "        td = reward + self.gamma * best_next - self.q[sk][a_idx]\n",
    "        self.q[sk][a_idx] += self.alpha * td\n",
    "\n",
    "class MonteCarloAgent:\n",
    "    def __init__(self, env, params):\n",
    "        self.env = env\n",
    "        self.returns = defaultdict(list)\n",
    "        self.Q = defaultdict(lambda: np.zeros(len(DEF_ACTIONS)))\n",
    "        self.gamma = params.get(\"gamma\", 0.99)\n",
    "        self.epsilon = params.get(\"epsilon\", 0.2)\n",
    "\n",
    "    def choose_action(self, state):\n",
    "        if random.random() < self.epsilon:\n",
    "            return random.choice(DEF_ACTIONS)\n",
    "        return DEF_ACTIONS[int(np.argmax(self.Q[state]))]\n",
    "\n",
    "    def learn_episode(self, episode):  # episode = list of (s,a,r)\n",
    "        G = 0\n",
    "        visited = set()\n",
    "        for s,a,r in reversed(episode):\n",
    "            G = self.gamma * G + r\n",
    "            if (s,a) not in visited:\n",
    "                self.returns[(s,a)].append(G)\n",
    "                self.Q[s][DEF_ACTIONS.index(a)] = np.mean(self.returns[(s,a)])\n",
    "                visited.add((s,a))\n",
    "\n",
    "class ActorCriticAgent:\n",
    "    def __init__(self, env, params):\n",
    "        self.env = env\n",
    "        self.actor = defaultdict(lambda: np.zeros(len(DEF_ACTIONS)))  # preferences\n",
    "        self.critic = defaultdict(float)\n",
    "        self.alpha = params.get(\"alpha\", 0.001)\n",
    "        self.beta = params.get(\"beta\", 0.01)\n",
    "        self.gamma = params.get(\"gamma\", 0.99)\n",
    "        self.epsilon = params.get(\"epsilon\", 0.2)\n",
    "\n",
    "    def softmax(self, prefs):\n",
    "        ex = np.exp(prefs - np.max(prefs))\n",
    "        probs = ex / np.sum(ex)\n",
    "        return probs\n",
    "\n",
    "    def choose_action(self, state):\n",
    "        prefs = self.actor[state]\n",
    "        probs = self.softmax(prefs)\n",
    "        if random.random() < self.epsilon:\n",
    "            return random.choice(DEF_ACTIONS)\n",
    "        return np.random.choice(DEF_ACTIONS, p=probs)\n",
    "\n",
    "    def learn_step(self, state, action, reward, next_state):\n",
    "        s = state; ns = next_state\n",
    "        a_idx = DEF_ACTIONS.index(action)\n",
    "        td_target = reward + self.gamma * self.critic[ns]\n",
    "        td_error = td_target - self.critic[s]\n",
    "        # update critic\n",
    "        self.critic[s] += self.beta * td_error\n",
    "        # update actor preferences\n",
    "        prefs = self.actor[s]\n",
    "        probs = self.softmax(prefs)\n",
    "        for i in range(len(prefs)):\n",
    "            if i == a_idx:\n",
    "                prefs[i] += self.alpha * td_error * (1 - probs[i])\n",
    "            else:\n",
    "                prefs[i] -= self.alpha * td_error * probs[i]\n",
    "        self.actor[s] = prefs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c40ee1",
   "metadata": {},
   "source": [
    "## TRAINING LOOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "123ae78b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------- CELL 4: TRAINING LOOP -----------------\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "import time\n",
    "\n",
    "def scripted_shooter_policy(env):\n",
    "    \"\"\"\n",
    "    Simple scripted shooter for training:\n",
    "    - Move up/down randomly, sometimes move toward hoop then shoot when forward enough.\n",
    "    - Returns tuple (action_shooter_str, shoot_boolean)\n",
    "    \"\"\"\n",
    "    shoot_prob = 0.08\n",
    "    move = random.choice([\"STAY\",\"UP\",\"DOWN\",\"LEFT\",\"RIGHT\",\"STAY\"])\n",
    "    if random.random() < 0.25:\n",
    "        move = \"RIGHT\"\n",
    "    shoot = False\n",
    "    if env.shooter.centerx > env.hoop_x - 220 and random.random() < shoot_prob:\n",
    "        shoot = True\n",
    "    return move, shoot\n",
    "\n",
    "def train(env, agent, episodes=200, render=True):\n",
    "    rewards_history = []\n",
    "\n",
    "    # keep cumulative stats here (not reset every env.reset)\n",
    "    total_shooter_score = 0\n",
    "    total_defender_blocks = 0\n",
    "    cumulative_reward = 0   # <-- NEW: running reward tracker\n",
    "\n",
    "    for ep in range(1, episodes+1):\n",
    "        # reset env (but do NOT wipe global counters)\n",
    "        env.reset(shooter_speed=MENU[\"params\"].get(\"shooter_speed\"),\n",
    "                  defender_speed=MENU[\"params\"].get(\"defender_speed\"),\n",
    "                  ball_speed=MENU[\"params\"].get(\"ball_speed\"))\n",
    "\n",
    "        env.episode = ep  # ensure correct episode sync\n",
    "        done = False\n",
    "        ep_reward = 0\n",
    "        mc_episode = []\n",
    "\n",
    "        while not done:\n",
    "            s = env._get_state()\n",
    "            action_def = agent.choose_action(s)\n",
    "\n",
    "            action_shooter, shoot = scripted_shooter_policy(env)\n",
    "\n",
    "            next_s, reward, done, info = env.step(\n",
    "                action_defender=action_def,\n",
    "                action_shooter=action_shooter,\n",
    "                shoot=shoot\n",
    "            )\n",
    "            ep_reward += reward\n",
    "            cumulative_reward += reward   # <-- Add to running total\n",
    "\n",
    "            if isinstance(agent, QLearningAgent):\n",
    "                agent.learn_step(s, action_def, reward, next_s)\n",
    "            elif isinstance(agent, ActorCriticAgent):\n",
    "                agent.learn_step(s, action_def, reward, next_s)\n",
    "            elif isinstance(agent, MonteCarloAgent):\n",
    "                mc_episode.append((s, action_def, reward))\n",
    "\n",
    "            if render:\n",
    "                env.render()\n",
    "\n",
    "            for ev in pygame.event.get():\n",
    "                if ev.type == pygame.QUIT:\n",
    "                    pygame.quit(); sys.exit()\n",
    "\n",
    "        if isinstance(agent, MonteCarloAgent) and mc_episode:\n",
    "            agent.learn_episode(mc_episode)\n",
    "\n",
    "        rewards_history.append(ep_reward)\n",
    "\n",
    "        # update cumulative totals\n",
    "        total_shooter_score += env.shooter_score\n",
    "        total_defender_blocks += env.defender_blocks\n",
    "\n",
    "        # --- Notebook logging output (sync with UI scoreboard) ---\n",
    "        print(f\"Episode {ep}/{episodes} | \"\n",
    "              f\"Shooter Total Score: {total_shooter_score} | \"\n",
    "              f\"Defender Total Blocks: {total_defender_blocks} | \"\n",
    "              f\"Reward: {cumulative_reward} | \"   # <-- running reward\n",
    "              f\"Last Reward: {env.last_reward}\")  # <-- per-step reward\n",
    "\n",
    "        if ep % 20 == 0:\n",
    "            time.sleep(0.2)\n",
    "\n",
    "    # plot rewards after training\n",
    "    plt.figure()\n",
    "    plt.plot(rewards_history)\n",
    "    plt.title(\"Rewards per Episode\")\n",
    "    plt.xlabel(\"Episode\")\n",
    "    plt.ylabel(\"Reward\")\n",
    "    plt.show()\n",
    "\n",
    "    return agent, rewards_history\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c95e073",
   "metadata": {},
   "source": [
    "## MAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "351c6f80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training: Actor-Critic for 50 episodes\n",
      "Episode 1/50 | Shooter Total Score: 0 | Defender Total Blocks: 0 | Reward: 0 | Last Reward: 0\n",
      "Episode 2/50 | Shooter Total Score: 1 | Defender Total Blocks: 0 | Reward: -10 | Last Reward: -10\n",
      "Episode 3/50 | Shooter Total Score: 1 | Defender Total Blocks: 0 | Reward: -10 | Last Reward: 0\n",
      "Episode 4/50 | Shooter Total Score: 1 | Defender Total Blocks: 0 | Reward: -10 | Last Reward: 0\n",
      "Episode 5/50 | Shooter Total Score: 1 | Defender Total Blocks: 0 | Reward: -10 | Last Reward: 0\n",
      "Episode 6/50 | Shooter Total Score: 1 | Defender Total Blocks: 0 | Reward: -10 | Last Reward: 0\n",
      "Episode 7/50 | Shooter Total Score: 1 | Defender Total Blocks: 0 | Reward: -10 | Last Reward: 0\n",
      "Episode 8/50 | Shooter Total Score: 1 | Defender Total Blocks: 0 | Reward: -10 | Last Reward: 0\n",
      "Episode 9/50 | Shooter Total Score: 1 | Defender Total Blocks: 0 | Reward: -10 | Last Reward: 0\n",
      "Episode 10/50 | Shooter Total Score: 1 | Defender Total Blocks: 0 | Reward: -10 | Last Reward: 0\n",
      "Episode 11/50 | Shooter Total Score: 2 | Defender Total Blocks: 0 | Reward: -20 | Last Reward: -10\n",
      "Episode 12/50 | Shooter Total Score: 2 | Defender Total Blocks: 0 | Reward: -20 | Last Reward: 0\n",
      "Episode 13/50 | Shooter Total Score: 2 | Defender Total Blocks: 0 | Reward: -20 | Last Reward: 0\n",
      "Episode 14/50 | Shooter Total Score: 2 | Defender Total Blocks: 0 | Reward: -20 | Last Reward: 0\n",
      "Episode 15/50 | Shooter Total Score: 2 | Defender Total Blocks: 0 | Reward: -20 | Last Reward: 0\n",
      "Episode 16/50 | Shooter Total Score: 2 | Defender Total Blocks: 0 | Reward: -20 | Last Reward: 0\n",
      "Episode 17/50 | Shooter Total Score: 2 | Defender Total Blocks: 0 | Reward: -20 | Last Reward: 0\n",
      "Episode 18/50 | Shooter Total Score: 2 | Defender Total Blocks: 0 | Reward: -20 | Last Reward: 0\n",
      "Episode 19/50 | Shooter Total Score: 2 | Defender Total Blocks: 0 | Reward: -20 | Last Reward: 0\n",
      "Episode 20/50 | Shooter Total Score: 2 | Defender Total Blocks: 0 | Reward: -20 | Last Reward: 0\n",
      "Episode 21/50 | Shooter Total Score: 2 | Defender Total Blocks: 0 | Reward: -20 | Last Reward: 0\n",
      "Episode 22/50 | Shooter Total Score: 2 | Defender Total Blocks: 0 | Reward: -20 | Last Reward: 0\n",
      "Episode 23/50 | Shooter Total Score: 2 | Defender Total Blocks: 0 | Reward: -20 | Last Reward: 0\n",
      "Episode 24/50 | Shooter Total Score: 2 | Defender Total Blocks: 0 | Reward: -20 | Last Reward: 0\n",
      "Episode 25/50 | Shooter Total Score: 3 | Defender Total Blocks: 0 | Reward: -30 | Last Reward: -10\n",
      "Episode 26/50 | Shooter Total Score: 3 | Defender Total Blocks: 0 | Reward: -30 | Last Reward: 0\n",
      "Episode 27/50 | Shooter Total Score: 3 | Defender Total Blocks: 0 | Reward: -30 | Last Reward: 0\n",
      "Episode 28/50 | Shooter Total Score: 3 | Defender Total Blocks: 0 | Reward: -30 | Last Reward: 0\n",
      "Episode 29/50 | Shooter Total Score: 3 | Defender Total Blocks: 0 | Reward: -30 | Last Reward: 0\n",
      "Episode 30/50 | Shooter Total Score: 3 | Defender Total Blocks: 0 | Reward: -30 | Last Reward: 0\n",
      "Episode 31/50 | Shooter Total Score: 4 | Defender Total Blocks: 0 | Reward: -40 | Last Reward: -10\n",
      "Episode 32/50 | Shooter Total Score: 4 | Defender Total Blocks: 0 | Reward: -40 | Last Reward: 0\n",
      "Episode 33/50 | Shooter Total Score: 4 | Defender Total Blocks: 0 | Reward: -40 | Last Reward: 0\n",
      "Episode 34/50 | Shooter Total Score: 4 | Defender Total Blocks: 0 | Reward: -40 | Last Reward: 0\n",
      "Episode 35/50 | Shooter Total Score: 4 | Defender Total Blocks: 0 | Reward: -40 | Last Reward: 0\n",
      "Episode 36/50 | Shooter Total Score: 4 | Defender Total Blocks: 0 | Reward: -40 | Last Reward: 0\n",
      "Episode 37/50 | Shooter Total Score: 5 | Defender Total Blocks: 0 | Reward: -50 | Last Reward: -10\n",
      "Episode 38/50 | Shooter Total Score: 5 | Defender Total Blocks: 0 | Reward: -50 | Last Reward: 0\n",
      "Episode 39/50 | Shooter Total Score: 5 | Defender Total Blocks: 0 | Reward: -50 | Last Reward: 0\n",
      "Episode 40/50 | Shooter Total Score: 6 | Defender Total Blocks: 0 | Reward: -60 | Last Reward: -10\n",
      "Episode 41/50 | Shooter Total Score: 6 | Defender Total Blocks: 0 | Reward: -60 | Last Reward: 0\n",
      "Episode 42/50 | Shooter Total Score: 6 | Defender Total Blocks: 0 | Reward: -60 | Last Reward: 0\n",
      "Episode 43/50 | Shooter Total Score: 6 | Defender Total Blocks: 0 | Reward: -60 | Last Reward: 0\n",
      "Episode 44/50 | Shooter Total Score: 6 | Defender Total Blocks: 0 | Reward: -60 | Last Reward: 0\n",
      "Episode 45/50 | Shooter Total Score: 6 | Defender Total Blocks: 0 | Reward: -60 | Last Reward: 0\n",
      "Episode 46/50 | Shooter Total Score: 6 | Defender Total Blocks: 0 | Reward: -60 | Last Reward: 0\n",
      "Episode 47/50 | Shooter Total Score: 7 | Defender Total Blocks: 0 | Reward: -70 | Last Reward: -10\n",
      "Episode 48/50 | Shooter Total Score: 7 | Defender Total Blocks: 0 | Reward: -70 | Last Reward: 0\n",
      "Episode 49/50 | Shooter Total Score: 7 | Defender Total Blocks: 0 | Reward: -70 | Last Reward: 0\n",
      "Episode 50/50 | Shooter Total Score: 7 | Defender Total Blocks: 0 | Reward: -70 | Last Reward: 0\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training finished.\n"
     ]
    }
   ],
   "source": [
    "# ----------------- CELL 5: MAIN RUNNER -----------------\n",
    "import pygame\n",
    "\n",
    "# Create environment\n",
    "env = BasketballEnv(CONFIG)\n",
    "\n",
    "trained_agent = None\n",
    "\n",
    "if MENU[\"mode\"] == \"Train\":\n",
    "    # instantiate the chosen agent\n",
    "    params = {\n",
    "        \"alpha\": MENU[\"params\"].get(\"alpha\", CONFIG[\"ALPHA\"]),\n",
    "        \"gamma\": MENU[\"params\"].get(\"gamma\", CONFIG[\"GAMMA\"]),\n",
    "        \"epsilon\": MENU[\"params\"].get(\"epsilon\", CONFIG[\"EPSILON\"])\n",
    "    }\n",
    "    alg = MENU[\"algorithm\"]\n",
    "    print(f\"Starting training: {alg} for {MENU['params'].get('episodes')} episodes\")\n",
    "    if alg == \"Q-Learning\":\n",
    "        agent = QLearningAgent(env, {\"alpha\":params[\"alpha\"], \"gamma\":params[\"gamma\"], \"epsilon\":params[\"epsilon\"]})\n",
    "    elif alg == \"Monte Carlo\":\n",
    "        agent = MonteCarloAgent(env, {\"gamma\":params[\"gamma\"], \"epsilon\":params[\"epsilon\"]})\n",
    "    elif alg == \"Actor-Critic\":\n",
    "        agent = ActorCriticAgent(env, {\"alpha\":params[\"alpha\"], \"gamma\":params[\"gamma\"], \"epsilon\":params[\"epsilon\"], \"beta\":0.01})\n",
    "    else:\n",
    "        raise ValueError(\"Unknown algorithm\")\n",
    "\n",
    "    trained_agent, rewards = train(env, agent, episodes=MENU[\"params\"].get(\"episodes\", 100), render=True)\n",
    "    print(\"Training finished.\")\n",
    "\n",
    "    # After training you can proceed to manual Play or stop. We'll keep trained_agent in variable.\n",
    "\n",
    "elif MENU[\"mode\"] == \"Play\":\n",
    "    manual_def = MENU[\"params\"].get(\"manual_defender\", False)\n",
    "    print(\"Starting Play mode. Controls: Shooter = WASD, Shoot=SPACE. Defender = Arrow keys (if manual) or Agent (if trained).\")\n",
    "    # If an agent was trained earlier in this session, use it; otherwise fallback to random agent\n",
    "    if trained_agent is None:\n",
    "        # create a simple random Q agent (no training) as fallback\n",
    "        trained_agent = QLearningAgent(env, {\"alpha\":0.1,\"gamma\":0.99,\"epsilon\":0.0})\n",
    "\n",
    "    running = True\n",
    "    clock = pygame.time.Clock()\n",
    "    while running:\n",
    "        s = env._get_state()\n",
    "        # handle events\n",
    "        move_shooter = None\n",
    "        shoot_flag = False\n",
    "        move_defender = None\n",
    "        for ev in pygame.event.get():\n",
    "            if ev.type == pygame.QUIT:\n",
    "                running = False\n",
    "            if ev.type == pygame.KEYDOWN:\n",
    "                if ev.key == pygame.K_SPACE:\n",
    "                    shoot_flag = True\n",
    "\n",
    "        keys = pygame.key.get_pressed()\n",
    "        # Shooter (human) WASD\n",
    "        if keys[pygame.K_w]: move_shooter = \"UP\"\n",
    "        elif keys[pygame.K_s]: move_shooter = \"DOWN\"\n",
    "        elif keys[pygame.K_a]: move_shooter = \"LEFT\"\n",
    "        elif keys[pygame.K_d]: move_shooter = \"RIGHT\"\n",
    "        else: move_shooter = \"STAY\"\n",
    "\n",
    "        # Defender manual or agent\n",
    "        if manual_def:\n",
    "            if keys[pygame.K_UP]: move_defender = \"UP\"\n",
    "            elif keys[pygame.K_DOWN]: move_defender = \"DOWN\"\n",
    "            elif keys[pygame.K_LEFT]: move_defender = \"LEFT\"\n",
    "            elif keys[pygame.K_RIGHT]: move_defender = \"RIGHT\"\n",
    "            else: move_defender = \"STAY\"\n",
    "        else:\n",
    "            # agent action\n",
    "            move_defender = trained_agent.choose_action(s)\n",
    "\n",
    "        # step env\n",
    "        next_s, reward, done, info = env.step(action_defender=move_defender, action_shooter=move_shooter, shoot=shoot_flag)\n",
    "        env.render(episode=None)\n",
    "\n",
    "        if done:\n",
    "            # Print episode outcome to notebook output (you requested prints go only to cell output)\n",
    "            print(f\"Play round result -> reward: {reward} | Blocks(this round): {info.get('blocks')} | Shooter score(this round): {info.get('shooter_score')}\")\n",
    "            # short pause then reset\n",
    "            time.sleep(0.6)\n",
    "            env.reset()\n",
    "        clock.tick(CONFIG[\"FPS\"])\n",
    "\n",
    "    pygame.quit()\n",
    "else:\n",
    "    raise ValueError(\"MENU mode not set correctly. Re-run Cell 1.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "olympiaCOM222ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
